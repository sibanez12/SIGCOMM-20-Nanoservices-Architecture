\begin{abstract}
Nanoservices are highly parallelizable, compute intensive applications with a cache resident working set and sub-microsecond response times. We believe that nanoservices will become popular in the future for two main reasons. One, Moore's Law is preventing increases in compute speed so we cannot rely on faster processors for performance gains. Two, many applications have inherent parallelizability that cannot be harnessed today because of large, unpredictable network delays and large overheads for small messages. In order to make nanoservices a reality, we need a new networking-optimized compute platform. Thus, in this paper we present the Nanoservice Processing Unit (NanoPU). The NanoPU has the following characteristics: a fast path between the network and the core of the CPU to minimize average communication latency, and NIC-driven thread scheduling to minimize tail response times. The NanoPU provides an order of magnitude lower average and tail latency than existing systems for nanoservice applications.
\end{abstract}